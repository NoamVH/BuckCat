<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <script type="text/javascript" src="{{ url_for('static', filename='overlay.js') }}"></script>
    <link rel="stylesheet" href="{{ url_for('static', filename='main.css') }}">
    <link rel="stylesheet" href="{{ url_for('static', filename='explanation.css')}}">
    <link rel="shortcut icon" href="{{ url_for('static', filename='CatFavicon.png') }}">
    <!--
        Set a link to a stylesheet as you would for any CSS file, but use the url_for method to be rendered by Flask when initializing the webapp,
        the argument for the static folder and the name of the file itself need to be set.
    -->
    <title>BuckCat - Explanation</title>
</head>
<body>
    <div class="overlay"></div>
    
    <div class="overlayContent">
        <img class="imgBig" src="" alt="">
        
        <div style="font-size: 22px; background-color: rgb(26, 25, 25);">
            Click the image again in order to close the overlay.
        </div>
    </div>

    <div id="Main">
        <div>
            <h1>
                What's Happening Here?
            </h1>
        </div>
        <div>
            <div>
                <div>
                    <h2>
                        Introduction
                    </h2>
                </div>
                <div>
                    <p>
                        This page will explain what is the BuckCat and how it works. <br>
                        If you just want more cats you can go back <a href="/">here</a>!
                    </p>
                    <p>
                        In 2023, I was challenged to create a certain environment in Amazon Web Service (AWS):
                    </p>
                    <p>
                        <ul>
                            <li>Create two Virtual Machines (VMs, or Instances as they are called in AWS).</li>
                            <li>Add a secrets manager (Key Management Server - KMS) and storage (S3).</li>
                            <li>Make one instance accessible through the internet and the second inaccessible.</li>
                        </ul>
                    </p>
                    <p>
                        Recently, I decided to bring the project back to life on Google Cloud Platform (GCP), with the same goals, only 100% based IaC with Terraform, without using the portal (or "Console" as Google call it for some reason), or the gcloud CLI even once.
                    </p>
                    <p>
                        The idea of the challenge was to get myself familiar with AWS, after getting some courses and experience with Azure at the time.
                        This time the idea was to get myself familiar with GCP, while making all of the required provisioning with Terraform, while keeping security best practices as much as possible.
                    </p>
                    <p> 
                        The challenge itself seemed simple enough, but it felt a little bit "empty" just provisioning the environment, so I decided to give it some life with this simple application.
                    </p>
                    <p>
                        It should be noted that the main goal of this little project is the environment and learning how to work with AWS/GCP, the application was a secondary goal.
                    </p>
                </div>
                <div>
                    <h3>
                        Update v4.0 - A Full Rewrite of the Project with IaC based on Terraform
                    </h3>
                </div>
                <div>
                    <p>
                        As explained above, all of the infrastructure was provisioned by using Terraform, there was no use of GCP' portal (Or console as they call it for some reason).
                        The code was rewrote from scratch for two reason - because of the usage of GCP's Python client libraries and because I can make the code cleaner, since my code abilities improved since last time.
                    </p>
                </div>
            </div>
            <div>
                <div>
                    <h2>How Does This Work</h2>
                </div>
                <div>
                    <h3>
                        Overview
                    </h3>
                </div>
                <div>
                    <p>
                        This application consists of a frontend service (a VM accessible from the internet, that runs a docker-container) and a backend service (the VM inaccessible from the internet, that also runs a docker-container).
                        Only the backend server is able to access the application's resources (the BuckCat).
                        The backend and frontend services communicate with each other by using GCP's Pub/Sub service, which allows the backend service to be completely isolated regarding ingress traffic (with the exception of SSH from my home network).
                    </p>
                    <p>
                        The general idea of the solution works as such:
                    </p>
                    <div id="grid" class="container">
                        <img class="imgSmall" src="{{ solution_image }}" alt="">
                    </div>
                    <div style="text-align: center;"> Click the image in order to view it at full size.</div>
                    <p>
                        <ul>
                            <li>User reaches the frontend service from the internet.</li>
                            <li>The frontend server sends the user this web page.</li>
                            <li>When the user clicks the "Pull Cat" button, the frontend server sends a request to the backend server through a Pub/Sub topic for cat requests.</li>
                            <li>The backend server listens for messages in the Pub/Sub topic, creates a signed temporary URL for the required cat, and sends it back to the frontend server through another Pub/Sub topic for cat URLs.</li>
                            <li>The frontend server presents the image to the user by using the temporary URL.</li>
                        </ul>
                    </p>
                </div>
                <div>
                    <h3>
                        A Deeper Dive
                    </h3>
                </div>
                <div>
                    <p>
                        Now it's possible to look into each component indvidually, let's use this table:
                    </p>
                    <p>
                        <table>
                            <tr>
                                <th>Frontend service</th>
                                <th>Backend service</th>
                            </tr>
                            <tr>
                                <td>
                                    <ul>
                                        <li>Runs on an e2-micro VM that is based on Debian Cloud, a Linux distribution optimized for running containers.</li>
                                        <li>Runs a container with an application written in Python, HTML and CSS:
                                        <li>Uses Flask and GCP's client Libraries.</li>
                                        <li>When the "Pull Cat" button is clicked, sends a cat request to the backend service through GCP Pub/Sub through a 'cats requests' topic.</li>
                                        <li>Pulls a cat URL from the "cats URLs" Pub/Sub topic, and uses it to present the cat to the user.</li>
                                        <li>Is within a Frontend VPC (Virtual Private Cloud) with a FW that allows HTTP requests from the internet, IAP (Identity-Aware Proxy) access, and SSH from my own home network.</li>
                                    </ul>
                                </td>
                                <td>
                                    <ul>
                                        <li>Runs on an e2-micro VM that is based on Debian Cloud, a Linux distribution optimized for running containers.</li>
                                        <li>Is assigned an IAM (GCP's Identity & Access Management) role that allows it to read information from the BuckCat and sign tokens.</li>
                                        <li>Runs a container with an application written in Python:</li>
                                        <li>Uses GCP's Python Client Library, which runs on a conatiner.</li>
                                        <li>Sends signed blob URLs to frontend with GCP Pub/Sub 'cats URLs' topic.</li>
                                    </ul>
                                </td>
                            </tr>
                        </table>
                    </p>
                </div>
                <div>
                    <div>
                        <h3>
                            Automation - CI/CD Pipelines with GitHub Actions and Google Artifactory Registry
                        </h3>
                    </div>
                    <div>
                        <p>
                            Deploying changes in the application manually is tedious, so a CI/CD process makes things quick and easy.
                        </p>
                        <p>
                            The existing pipelines were split into frontend and backend pipelines (before that they were the same pipelines), and rewritten to integrate with GCP.
                            The CD process is a bit more convoluted then normal regarding deployment, since the project utilizes conatiners that run inside of VMS.
                            It would've been a simpler process if the project was based on Kubernetes or GCP Run (which would simply require restarting the service).
                            This decision was made out of pricing considerations, more on that later.
                        </p>
                        <p>
                            The CI/CD process was created with four YAML files that run in GitHub Actions:<br>
                            <ul>
                                <li>The CI pipelines run when a new commit is pushed to the main branch in GitHub, depending on the directories that the commit modified. They container images and push them to GAR.</li>
                                <li>The CD pipelines runs when the CI pipelines are completed, they connect with SSH to each service through IAP, and tells it to run a bash script.</li>
                                <li>The CD pipelines stop the running container, prune all inactive containers, prune all inactive images, and runs the latest image (which triggers an automatic pull).</li>
                            </ul>
                        </p>
                        <p>
                            <b>CI Pipelines Steps</b>
                            <ul>
                                <li>Run when a new commit is added to the main branch to the respective frontend or backend directory, run on an Ubuntu server.</li>
                                <li>Checkout the latest commit on the main branch.</li>
                                <li>Auhthenticate to GCP by using a workload identity federation that impersonates a service account for short-term tokens.</li>
                                <li>Login to GAR by using the workload identity service account.</li>
                                <li>Build, tag, and push the respective container image to GAR with Docker Compose.</li>
                                <li>Unrelated note - old untagged images are deleted automatically by GAR by using a cleanup policy, that is defined with Terraform as part of the resource.</li>
                            </ul>
                        </p>
                        <p>
                            <b>CD Pipelines Steps</b>
                            <ul>
                                <li>Run when the respective CI Pipeline is done successfully, run on an Ubuntu server.</li>
                                <li>Checkout the latest commit on the main branch.</li>
                                <li>Auhthenticate to GCP by using a workload identity federation that impersonates a service account for short-term tokens.</li>
                                <li>SSH to the respective machine through IAP, stop the running container, prune all containers and images.</li>
                                <li>Pull and run the latest container image.</li>
                            </ul>
                        </p>
                        <p>
                            The CI/CD YAML files can be found <a href="https://github.com/NoamVH/BuckCat/tree/main/.github/workflows">here</a>.
                        </p>
                    </div>
                    <div>
                        <h3>
                            Identity and Access Management
                        </h3>
                    </div>
                    <div>
                        <p>
                            One of the goals of the project was to comply with security best-practices as much as possible. Unfortunately, there are many 'guides' on the internet (I'm looking at YOU Medium, literally the hub of mediocracy),<br>
                            that spread some simple 'solutions', that while they are using the least secure methods possible, that may be good for beginners who want to experiment, but many of these 'solutoins' also get to production environments.
                        </p>
                        <p>
                            Google's documentation states* the best practices of different processes and components, as well as the predefined roles that exist for each resource and their perimssions.<br>
                            The IAM roles divide to three categories:
                            <ul>
                                <li><b>Development Permissions</b> - a service account used for local testing.</li>
                                <ul>
                                    <li><code>storage.objectViewer</code> - allows viewing and downloading a bucket's contents.</li>
                                    <li><code>pubsub.subscriber</code> and <code>pubsub.publisher</code> allows reading and writing messages to GCP Pub/Sub topics.</li>
                                </ul>
                                <li><b>Workload Identity Federation</b> - allows GitHub actions (or other on-premises/multi-cloud resources) to authenticate with GCP, the main advantage of this practice is that no credentials need to be taken out of GCP (<a href="https://cloud.google.com/iam/docs/workload-identity-federation">Reference</a>).</li>
                                <ul>
                                    <li>The workload identity is recognized by two attributes, which are defined by two assertions - <code>assertion.repository_owner_id</code> and <code>assertion.repository_id</code> this limits authentication to the BuckCat's code repository only.</li>
                                    <li>The workload identity has a dedicated service account that is attached to it, which is done with the <code>google_service_account_iam_member</code> Terraform resource, the role that is defined for that resource is <code>iam.workloadIdentityUser</code>.</li>
                                    <li><code>artifatregistry.repoAdmin</code> is given to the workload identity's service account for reading, writing, and deleting container images from GAR</li>
                                    <li><code>compute.instanceAdmin.v1</code> is given twice, one for each compute engine, in order to allow SSH connection to the compute instance (this one was weird for me, administrator seems excessive, but this is what the instructions in <a href="https://cloud.google.com/compute/docs/access/iam#connectinginstanceadmin">Google's documentation</a> say, and it wouldn't work otherwise).</li>
                                    <li><code>compute.viewer</code> is given on the project level, this is also required for GitHub to be able to attempt a connection with SSH by using gcloud, otherwise it woulnd't be able to find the machine and the SSH attempt would fail.</li>
                                    <li><code>iam.serviceAccountUser</code> is given to the GitHub workload identity service account, which connects it to the machines' service account (more on that later), this is another (somewhat strange) requirement by Google, which allows GitHub to act on behalf of the machine's service account.</li>
                                    <li><code>iap.tunnelResourceAccessor</code> is given in order to allow creating an SSH tunnel towards the machines, which as mentioned before, have FW ingress rules that allow IAP to connect to them.</li>
                                </ul>
                                <li><b>Compute Instance Permissions</b> - allows a service account that is attached to the servers to interact with resources. This service account has the same permissions of the local development service account, with a few additons:</li>
                                <ul>
                                    <li><code>artifactregistry.reader</code> allows the servers to pull container images from GAR.</li>
                                    <li><code>iam.serviceAccountTokenCreator</code> allows the backend server to sign tokens for the temporary URLs.</li>
                                </ul>
                            </ul>
                            And with that, all resources have the minimal permissions that allow them to do exactly what they need, and there's compliance with GCP's best practices, hurray!
                        </p>
                    </div>
            </div>
            <div>
                <div>
                    <h2>
                        Summary
                    </h2>
                </div>
                <div>
                    <p>
                        <ul>
                            <li>This original project consisted of an application that was deployed on AWS, the goal of the project was to get familiar with the AWS environment.</li>
                            <li>For the old explanation about the original project, see <a href="/aws-explanation">here</a>, the original code can also be found in a directory in the repository <a href="https://github.com/NoamVH/BuckCat/tree/main/AWS">here</a>.</li>
                            <li>The also include a CI/CD process which makes development comfortable.</li>
                            <li>The current project, was done within about three work days during November 2024, with semi-focus, whenever free time was available, on the original project in 2023 I was unemployed.</li>
                            <li>Most of that time was spent on configuring roles on IAM and figuring out Google's practices, rather than development.</li>
                            <li>This is the fourth version of the project, which deploys it on GCP by using Terraform, while complying with best-practices.</li>
                            <li>The project's source code can be found on <a href="https://github.com/NoamVH/BuckCat">GitHub</a>.</li>
                            <li>If you have any questions or comments, or are hiring, you can reach me via my <a href="https://www.linkedin.com/in/noamvh/">LinkedIn Profile.</a></li>
                            <li>If you want to click on the button more and see more cats, you can go back <a href="/">here</a>!</li>
                        </ul>
                    </p>
                </div>
            </div>
            <div>
                <h2>
                    Final Thoughts
                </h2>
            </div>
            <div>
                <p>
                    "Ugh". <br>
                    Has been my main thought while working on the recreation of this project on GCP. I'm writing this after I finished configuring automatic startup scripts for the two VMs in Terraform. Which was quite annoying.
                </p>
                <p>
                    This project isn't too complicated, and is comprised of fairly simple parts. When I saw that GCP are offering a free demo with ~$300 to use for three months, it heightened my expectations (I still tried expenses to be as little as possible).
                    Somehow, GCP got me quite frustrated, since even though I followed the documentation as much as possible, I would still get stuck at some parts, either due to documentation not mentioning important information, not being clear, or some components not being fully integrated.
                </p>
                <p>
                    I would say that the most frustrating aspect of this is that since the project is simple, I shouldn't get stuck at so many different steps, which heightens the frustration even more, as a potential customers that tries to demo GCP for himself, I'd expect a much better user experience.
                </p>
                <p>
                    Another aspect of that frustration is the fact that many of GCP's requirements aren't intuitive, or that they go against other things the GCP decided to design:
                </p>
                <p>
                    <ul>
                        <li>CORS-Cloud is a special VM image designed for running containers - but it can't run a start-up script for authenticating Docker as root, since the filesystem is read-only, and the "Run Container" configuration isn't available in Terraform. So I had to use Debian and install Docker from scratch as part of the startup script.</li>
                        <li>GCP's documentation set direct permissions for workload identity federation as best practice, over service account impersonation - only to discover that most permissions required for this (again, simple) project can only be given to a service account, not directly, which also added to a few hours of frustration.</li>
                        <li>GCP have the <code>gcloud ssh</code> command, that saves the need to create a private SSH key and having to protect it - However, <a href="https://github.com/google-github-actions/ssh-compute">Google's SSH Compute GitHub Action</a> requires a private SSH key, even though it essentially runs the <code>gcloud ssh</code> command.</li>
                        <li>GCP has an OSLogin role for Compute - but SSH connection requires <code>compute.instanceAdmin.v1</code> for some reason, along with other requirements <a href="https://cloud.google.com/compute/docs/access/iam#the_serviceaccountuser_role">that are mentioned in the documentation</a> but makes no intuitive sense.</li>
                    </ul>
                </p>
                <p>
                    These are a few of the main frustrations I experienced while trying to work out all of the permissions and intergrations, however, I don't recall at all having so much trouble while working with AWS, and I never experienced problems like that when working with Azure in my recent job, which makes me think that I myself might not (completely) be the problem, but GCP being either weird, or not doing something right (at least from my current perspective).
                </p>
                <p>
                    Aside of that, the project was fun and enriching, and got me to get to know GCP and play around with Terraform, while looking at cat pictures from time to time.
                </p>
                <p>
                    If I were a rich man (yabidabidabadabidabudabidabuda), I'd be able to make an even more simple set up that would prevent all of the frustration described above:
                    <ul>
                        <li>Apply the containers on GCP Cloud Run, which would reduce the need for provision VMs, the containers would start by the service, and updating the conatiner's image would simply require restarting them.</li>
                        <li>Apply the containers in Kubernetes, and use ArgoCD for GitOps, deployment would be done automatically, and updates would be done by modifying the requires kustomization files. Unfortunately, there doesn't seem to be a Minikube or k3s type of Kubernetes provision like the one in AWS.</li>
                        <li>Ideally, for this project's size, it would be best if the "Run Container" metadata configuration was available in Terraform, since then a simple restart to the VM would be sufficient for updating the container in the COS VM.</li>
                    </ul>
                </p>
            </div>
        </div>
        </div>
            <div>
                <div>
                    <h2>
                        Acknowledgement
                    </h2>
                </div>
                <div>
                    <p>
                        I would like to thank:
                    </p>
                    <p>
                        <ul>
                            <li>Roi - for inspiring this project (<a href="https://www.linkedin.com/in/roi-shraga/">LinkedIn</a>).</li>
                            <li>Tal - for technical advice and existing in general (<a href="https://www.linkedin.com/in/reverser/">LinkedIn</a> | <a href="https://taltechtreks.com/">Blog</a>  | <a href="https://bsky.app/profile/taltechtreks.com"> BlueSky</a>).</li>
                        </ul>
                    </p>
                </div>
            </div>
        </div>
    </div>
</body>
</html>
